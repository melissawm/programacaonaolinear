{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução <a id='introduction'></a>\n",
    "\n",
    "Métodos de otimização contínua buscam um minimizador local de uma função suave\n",
    "$$f: \\mathbb{R}^n \\to \\mathbb{R}.$$\n",
    "Em geral, $f$ é duas vezes continuamente diferenciável (mesmo se as derivadas não estiverem disponíveis ou seu cálculo seja inviável computacionalmente)\n",
    "\n",
    "Vamos falar sobre o método do Gradiente, ou Método de Cauchy. Assim, dado um ponto inicial $x^0\\in \\mathbb{R}^n$, procuramos gerar uma sequência de pontos $x^k\\in \\mathbb{R}^n$ tal que cada nova iteração é dada por \n",
    "$$x_{k+1} = x_k + \\alpha_k p_k$$\n",
    "em que $p_k$ é uma *direção de descida*, ou seja, é uma direção na qual sabemos que a função objetivo tem seu valor reduzido (ao menos localmente). Então, $p_k$ deve satisfazer a condição\n",
    "$$p_k^T\\nabla f(x_k) < 0.$$\n",
    "Em geral, $\\| p_k\\|_2=1$, e assim $\\alpha_k$ determina o tamanho do passo que será tomado nessa direção. \n",
    "\n",
    "Repetiremos essa iteração até que seja encontrado um ponto para o qual $\\nabla f(x_k)=0$ ou $|\\nabla f(x_k)|<\\epsilon$, em que $\\epsilon >0$ é alguma tolerância (em geral, algo em torno de $10^{-10}$, por exemplo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função de teste\n",
    "\n",
    "A <a href=\"https://en.wikipedia.org/wiki/Rosenbrock_function\">função de Rosenbrock</a> é uma função conhecida para se testar algoritmos de otimização irrestrita. A forma usual é \n",
    "$$f(x) = (1-x_0)^2 + \\beta(x_1-x_0^2)^2$$\n",
    "em que $\\beta$ é algum número real (normalmente positivo). Vamos usar $\\beta=10$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rosenbrock(x):\n",
    "    return (1-x[0])**2+10*(x[1]-x[0]**2)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, podemos calcular o valor da função de Rosenbrock em um determinado ponto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [2,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ao fazermos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rosenbrock(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Método do gradiente\n",
    "\n",
    "Conforme já discutido em aula, vamos usar aqui $p_k = -\\nabla f(x_k)$ em todas as iterações. Para isso, vamos definir uma função que calcula o gradiente da função:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradiente(x):\n",
    "    return np.asarray([2*x[0]-2-40*x[0]*(x[1]-x[0]**2), 20*(x[1]-x[0]**2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(observe que definimos a saída da função gradiente como uma ndarray, pois isso será necessário mais à frente)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Então, escolha um ponto inicial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A direção aqui será"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = -gradiente(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nessa direção, se tomarmos um passo com $\\alpha^k=1$, teremos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ponto_inicial = np.asarray(x)\n",
    "ponto_novo = ponto_inicial + p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ponto_novo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos ver na figura:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grafico_curvas(points):\n",
    "    x = np.linspace(-2, 2, 100)\n",
    "    y = np.linspace(-2, 2, 100)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    R = rosenbrock([X, Y])\n",
    "    plt.figure()\n",
    "    levels = [0, 0.1, 0.5, 1, 2, 5, 10, 20, 30, 50, 100]\n",
    "    plt.contour(X, Y, R, levels)\n",
    "\n",
    "    for point in points:\n",
    "        plt.plot(point[0], point[1], 'ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grafico_curvas((ponto_inicial, ponto_novo))\n",
    "plt.annotate(\"x_0\", ponto_inicial, xytext=ponto_inicial-np.asarray([0.3, 0]))\n",
    "plt.annotate(\"x_1\", ponto_novo, xytext=ponto_novo-np.asarray([0.2, 0.3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No entanto, um passo nessa direção na verdade *aumentou* o valor da função:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rosenbrock(ponto_inicial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rosenbrock(ponto_novo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backtracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Já vimos em aula que as condições de Wolfe garantem que poderemos encontrar um $alpha_k$ apropriado que (i) resulta em um *decréscimo suficiente* no valor da função objetivo; e (ii) satisfaz a condição de curvatura. No entanto, encontrar esse ponto diretamente pode ser difícil. \n",
    "\n",
    "Propomos então a estratégia seguinte: vamos escolher o maior valor de $\\alpha$ tal que $x_k+\\alpha p_k$ satisfaça a condição de decréscimo suficiente. (vamos criar uma função para esse procedimento para podermos utilizá-la novamente mais tarde):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscalinear(ponto_inicial, p, c1=1e-4):\n",
    "    alpha = 1 # A escolha do alpha inicial também pode ser discutida, \n",
    "              # mas aqui escolheremos simplesmente alpha=1.\n",
    "    f_inicial = rosenbrock(ponto_inicial)\n",
    "    grad_inicial = gradiente(ponto_inicial)\n",
    "    ponto_novo = ponto_inicial + alpha*p\n",
    "    while rosenbrock(ponto_novo) > f_inicial + c1*alpha*np.dot(grad_inicial, p):\n",
    "        alpha = 0.9*alpha\n",
    "        ponto_novo = ponto_inicial + alpha*p\n",
    "    return ponto_novo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ponto_novo = buscalinear(ponto_inicial, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ponto_novo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na figura:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grafico_curvas((ponto_inicial, ponto_novo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora sim:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rosenbrock(ponto_novo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos repetir o processo até que estejamos satisfeitos com o valor do gradiente da função. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metodo_do_gradiente(fun, grad, x, tolerancia_gradiente):\n",
    "    p = -grad(x)\n",
    "    while np.sqrt(p[0]**2+p[1]**2) > tolerancia_gradiente:\n",
    "        x = buscalinear(x, p)\n",
    "        p = -grad(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solucao = metodo_do_gradiente(rosenbrock, gradiente, ponto_inicial, 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De fato,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradiente(solucao)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, podemos modificar nosso método do gradiente para guardarmos todas as iteradas e observarmos o caminho do método do gradiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metodo_do_gradiente(fun, grad, x, tolerancia_gradiente):\n",
    "    iteradas = []\n",
    "    # iteradas é uma lista que guarda todos os pontos gerados pelo método\n",
    "    iteradas.append(x)\n",
    "    p = -grad(x)\n",
    "    while np.sqrt(p[0]**2+p[1]**2) > tolerancia_gradiente:\n",
    "        x = buscalinear(x, p)\n",
    "        iteradas.append(x)\n",
    "        p = -grad(x)\n",
    "    return x, iteradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solucao, iteradas = metodo_do_gradiente(rosenbrock, gradiente, ponto_inicial, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grafico_curvas(iteradas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok! Achamos uma solução. Mas o método não é muito bom: levamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(iteradas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "para encontrarmos a solução..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
